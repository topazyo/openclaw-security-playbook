# Docker Compose Configuration for ClawdBot - Hardened
# Version: 1.0.0
# Last Updated: February 14, 2026
#
# Security Features:
#   - Network isolation with multiple networks
#   - Resource limits (CPU, memory, PIDs)
#   - Health checks for all services
#   - Read-only root filesystems
#   - Minimal capabilities
#   - Secrets management
#   - Security scanning integration
#   - Logging and monitoring
#
# Usage:
#   docker-compose up -d
#   docker-compose ps
#   docker-compose logs -f clawdbot
#   docker-compose down

version: '3.9'

# ============================================================================
# SERVICES
# ============================================================================

services:
  # --------------------------------------------------------------------------
  # ClawdBot Gateway Service
  # --------------------------------------------------------------------------
  clawdbot-gateway:
    image: clawdbot/gateway:${CLAWDBOT_VERSION:-latest}
    build:
      context: .
      dockerfile: Dockerfile.hardened
      target: gateway
      args:
        - PYTHON_VERSION=3.11
        - BUILD_DATE=${BUILD_DATE}
        - VCS_REF=${VCS_REF}
    container_name: clawdbot-gateway
    hostname: gateway
    restart: unless-stopped

    # Security Configuration
    security_opt:
      - no-new-privileges:true
      - seccomp:./seccomp-profiles/clawdbot.json
      - apparmor=docker-default

    # User Configuration (non-root)
    user: "1000:1000"

    # Capabilities (minimal required)
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE  # Only if binding to port < 1024

    # Read-only root filesystem
    read_only: true

    # Temporary filesystems for writable directories
    tmpfs:
      - /tmp:rw,noexec,nosuid,size=100m
      - /var/run:rw,noexec,nosuid,size=10m
      - /var/cache:rw,noexec,nosuid,size=50m

    # Environment Variables
    environment:
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - GATEWAY_PORT=8443
      - GATEWAY_HOST=0.0.0.0
      - ENABLE_METRICS=true
      - ENABLE_TRACING=true
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1

    # Secrets (using Docker secrets instead of environment variables)
    secrets:
      - anthropic_api_key
      - openai_api_key
      - gateway_secret_key

    # Port Mapping (only expose what's needed)
    ports:
      - "8443:8443"  # Gateway HTTPS
      - "9090:9090"  # Metrics (Prometheus)

    # Networks
    networks:
      - frontend
      - backend
      - monitoring

    # Resource Limits
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
          pids: 100
        reservations:
          cpus: '0.5'
          memory: 512M

    # Health Check
    healthcheck:
      test: ["CMD", "curl", "-f", "https://localhost:8443/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

    # Volumes (read-only where possible)
    volumes:
      - type: bind
        source: ./config
        target: /app/config
        read_only: true
      - type: bind
        source: ./logs
        target: /app/logs
        read_only: false
      - type: tmpfs
        target: /app/tmp
        tmpfs:
          size: 100m

    # Logging Configuration
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=clawdbot-gateway"

    # Dependencies
    depends_on:
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy

    # Labels for service discovery
    labels:
      - "com.clawdbot.service=gateway"
      - "com.clawdbot.environment=${ENVIRONMENT:-production}"
      - "com.clawdbot.version=${CLAWDBOT_VERSION:-latest}"

  # --------------------------------------------------------------------------
  # ClawdBot Agent Service
  # --------------------------------------------------------------------------
  clawdbot-agent:
    image: clawdbot/agent:${CLAWDBOT_VERSION:-latest}
    build:
      context: .
      dockerfile: Dockerfile.hardened
      target: agent
      args:
        - PYTHON_VERSION=3.11
    container_name: clawdbot-agent
    hostname: agent
    restart: unless-stopped

    # Security Configuration
    security_opt:
      - no-new-privileges:true
      - seccomp:./seccomp-profiles/clawdbot.json

    user: "1000:1000"

    cap_drop:
      - ALL

    read_only: true

    tmpfs:
      - /tmp:rw,noexec,nosuid,size=200m
      - /var/run:rw,noexec,nosuid,size=10m

    environment:
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - GATEWAY_URL=https://clawdbot-gateway:8443
      - MAX_CONCURRENT_TASKS=5
      - TASK_TIMEOUT=300

    secrets:
      - anthropic_api_key
      - agent_auth_token

    networks:
      - backend
      - monitoring

    deploy:
      replicas: 2  # Scale for redundancy
      resources:
        limits:
          cpus: '1.5'
          memory: 1.5G
          pids: 50
        reservations:
          cpus: '0.25'
          memory: 256M

    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

    volumes:
      - type: bind
        source: ./agent-config
        target: /app/config
        read_only: true
      - type: volume
        source: agent-data
        target: /app/data
      - agent-tmp:/app/tmp

    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=clawdbot-agent"

    depends_on:
      clawdbot-gateway:
        condition: service_healthy
      redis:
        condition: service_healthy

  # --------------------------------------------------------------------------
  # Redis Cache Service
  # --------------------------------------------------------------------------
  redis:
    image: redis:7-alpine
    container_name: clawdbot-redis
    hostname: redis
    restart: unless-stopped

    security_opt:
      - no-new-privileges:true

    user: "999:999"  # Redis user

    read_only: true

    tmpfs:
      - /tmp:rw,noexec,nosuid,size=50m

    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD}
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
      --appendonly yes
      --appendfsync everysec
      --dir /data

    networks:
      - backend

    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
          pids: 20
        reservations:
          cpus: '0.1'
          memory: 128M

    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

    volumes:
      - redis-data:/data

    logging:
      driver: json-file
      options:
        max-size: "5m"
        max-file: "2"

  # --------------------------------------------------------------------------
  # PostgreSQL Database Service
  # --------------------------------------------------------------------------
  postgres:
    image: postgres:15-alpine
    container_name: clawdbot-postgres
    hostname: postgres
    restart: unless-stopped

    security_opt:
      - no-new-privileges:true

    user: "70:70"  # Postgres user

    read_only: true

    tmpfs:
      - /tmp:rw,noexec,nosuid,size=100m
      - /run/postgresql:rw,noexec,nosuid,size=10m

    environment:
      - POSTGRES_DB=clawdbot
      - POSTGRES_USER=clawdbot
      - PGDATA=/var/lib/postgresql/data/pgdata

    secrets:
      - postgres_password

    networks:
      - backend

    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
          pids: 100
        reservations:
          cpus: '0.25'
          memory: 256M

    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U clawdbot"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

    volumes:
      - postgres-data:/var/lib/postgresql/data
      - type: bind
        source: ./db-init
        target: /docker-entrypoint-initdb.d
        read_only: true

    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  # --------------------------------------------------------------------------
  # Prometheus Monitoring Service
  # --------------------------------------------------------------------------
  prometheus:
    image: prom/prometheus:latest
    container_name: clawdbot-prometheus
    hostname: prometheus
    restart: unless-stopped

    security_opt:
      - no-new-privileges:true

    user: "65534:65534"  # nobody user

    read_only: true

    tmpfs:
      - /tmp:rw,noexec,nosuid,size=50m

    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'

    ports:
      - "9091:9090"

    networks:
      - monitoring

    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
          pids: 50
        reservations:
          cpus: '0.1'
          memory: 128M

    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

    volumes:
      - type: bind
        source: ./monitoring/prometheus.yml
        target: /etc/prometheus/prometheus.yml
        read_only: true
      - prometheus-data:/prometheus

    logging:
      driver: json-file
      options:
        max-size: "5m"
        max-file: "2"

  # --------------------------------------------------------------------------
  # Grafana Visualization Service
  # --------------------------------------------------------------------------
  grafana:
    image: grafana/grafana:latest
    container_name: clawdbot-grafana
    hostname: grafana
    restart: unless-stopped

    security_opt:
      - no-new-privileges:true

    user: "472:472"  # Grafana user

    read_only: true

    tmpfs:
      - /tmp:rw,noexec,nosuid,size=50m
      - /var/lib/grafana/plugins:rw,noexec,nosuid,size=100m

    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_INSTALL_PLUGINS=
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=https://grafana.clawdbot.internal
      - GF_AUTH_ANONYMOUS_ENABLED=false

    ports:
      - "3000:3000"

    networks:
      - monitoring
      - frontend

    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
          pids: 50
        reservations:
          cpus: '0.1'
          memory: 128M

    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

    volumes:
      - grafana-data:/var/lib/grafana
      - type: bind
        source: ./monitoring/grafana-dashboards
        target: /etc/grafana/provisioning/dashboards
        read_only: true

    logging:
      driver: json-file
      options:
        max-size: "5m"
        max-file: "2"

    depends_on:
      - prometheus

  # --------------------------------------------------------------------------
  # Security Scanner Service (Trivy)
  # --------------------------------------------------------------------------
  trivy:
    image: aquasec/trivy:latest
    container_name: clawdbot-trivy
    hostname: trivy
    restart: "no"  # Run on-demand

    security_opt:
      - no-new-privileges:true

    user: "1000:1000"

    read_only: true

    tmpfs:
      - /tmp:rw,noexec,nosuid,size=500m

    command: ["server", "--listen", "0.0.0.0:8080"]

    networks:
      - monitoring

    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
          pids: 50
        reservations:
          cpus: '0.25'
          memory: 256M

    volumes:
      - trivy-cache:/root/.cache

    logging:
      driver: json-file
      options:
        max-size: "5m"
        max-file: "2"

# ============================================================================
# NETWORKS
# ============================================================================

networks:
  # Frontend network - external access
  frontend:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/24
    driver_opts:
      com.docker.network.bridge.name: clawdbot-frontend
      com.docker.network.bridge.enable_icc: "false"
      com.docker.network.bridge.enable_ip_masquerade: "true"

  # Backend network - internal services
  backend:
    driver: bridge
    internal: true  # No external access
    ipam:
      config:
        - subnet: 172.21.0.0/24
    driver_opts:
      com.docker.network.bridge.name: clawdbot-backend
      com.docker.network.bridge.enable_icc: "true"

  # Monitoring network - metrics collection
  monitoring:
    driver: bridge
    ipam:
      config:
        - subnet: 172.22.0.0/24
    driver_opts:
      com.docker.network.bridge.name: clawdbot-monitoring

# ============================================================================
# VOLUMES
# ============================================================================

volumes:
  # Persistent data volumes
  redis-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_DIR:-./data}/redis

  postgres-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_DIR:-./data}/postgres

  prometheus-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_DIR:-./data}/prometheus

  grafana-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_DIR:-./data}/grafana

  trivy-cache:
    driver: local

  agent-data:
    driver: local

  agent-tmp:
    driver: tmpfs
    driver_opts:
      type: tmpfs
      device: tmpfs
      o: size=100m,uid=1000,gid=1000

# ============================================================================
# SECRETS
# ============================================================================

secrets:
  anthropic_api_key:
    file: ./secrets/anthropic_api_key.txt

  openai_api_key:
    file: ./secrets/openai_api_key.txt

  gateway_secret_key:
    file: ./secrets/gateway_secret_key.txt

  agent_auth_token:
    file: ./secrets/agent_auth_token.txt

  postgres_password:
    file: ./secrets/postgres_password.txt

# ============================================================================
# CONFIGURATION NOTES
# ============================================================================
#
# Environment Variables:
#   CLAWDBOT_VERSION   - Version tag for ClawdBot images (default: latest)
#   ENVIRONMENT        - Deployment environment (production/staging/dev)
#   LOG_LEVEL          - Logging level (DEBUG/INFO/WARNING/ERROR)
#   DATA_DIR           - Host directory for persistent data
#   REDIS_PASSWORD     - Redis authentication password
#   GRAFANA_USER       - Grafana admin username
#   GRAFANA_PASSWORD   - Grafana admin password
#
# Security Features:
#   1. Network Isolation
#      - Separate networks for frontend, backend, and monitoring
#      - Backend network has no external access
#   
#   2. Resource Limits
#      - CPU limits prevent resource exhaustion
#      - Memory limits prevent OOM attacks
#      - PID limits prevent fork bombs
#   
#   3. Filesystem Security
#      - Read-only root filesystems where possible
#      - Temporary filesystems with noexec, nosuid
#      - Minimal writable mounts
#   
#   4. User Security
#      - All services run as non-root users
#      - Minimal capabilities (CAP_DROP ALL)
#      - no-new-privileges flag
#   
#   5. Secrets Management
#      - Secrets stored in files, not environment variables
#      - Mounted into containers securely
#   
#   6. Health Checks
#      - All critical services have health checks
#      - Automatic restart on failure
#   
#   7. Logging
#      - Centralized JSON logging
#      - Log rotation to prevent disk exhaustion
#
# Usage Examples:
#   # Start all services
#   docker-compose up -d
#   
#   # Check service status
#   docker-compose ps
#   
#   # View logs
#   docker-compose logs -f clawdbot-gateway
#   
#   # Scale agent service
#   docker-compose up -d --scale clawdbot-agent=3
#   
#   # Run security scan
#   docker-compose run trivy image clawdbot/gateway:latest
#   
#   # Stop all services
#   docker-compose down
#   
#   # Remove all data (WARNING: destructive)
#   docker-compose down -v
#
# Maintenance:
#   # Update images
#   docker-compose pull
#   docker-compose up -d
#   
#   # Backup data
#   docker-compose exec postgres pg_dump -U clawdbot > backup.sql
#   
#   # Restore data
#   docker-compose exec -T postgres psql -U clawdbot < backup.sql
#
